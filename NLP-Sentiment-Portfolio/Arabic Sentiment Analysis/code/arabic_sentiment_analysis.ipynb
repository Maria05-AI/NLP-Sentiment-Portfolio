{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "139dfa9e-876b-4c01-a222-00b068709828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created successfully.\n",
      "Model trained successfully.\n",
      "\n",
      "--- Live Inference ---\n",
      "Text: Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ Ø§Ù†Ù‡ Ø±Ø§Ø¦Ø¹\n",
      "Prediction: Negative (Confidence: 52.0%)\n",
      "------------------------------\n",
      "Text: Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ ÙˆÙ‡Ùˆ Ø³ÙŠØ¡ Ø¬Ø¯Ø§\n",
      "Prediction: Negative (Confidence: 96.6%)\n",
      "------------------------------\n",
      "Text: Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¬ÙŠØ¯Ù‡\n",
      "Prediction: Positive (Confidence: 94.7%)\n",
      "------------------------------\n",
      "Text: ÙƒØ§Ù†Øª Ø§Ù„ØªØ¬Ø±Ø¨Ø© ÙƒØ§Ø±Ø«ÙŠØ©\n",
      "Prediction: Negative (Confidence: 94.7%)\n",
      "------------------------------\n",
      "Text: ØªØ¬Ø±Ø¨Ø© Ø¬Ù…ÙŠÙ„Ø© Ùˆ Ø§Ù„Ù…Ù†ØªØ¬ Ø¬ÙŠØ¯\n",
      "Prediction: Positive (Confidence: 94.8%)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Project: Arabic Sentiment Analysis (Mini-Scale)\n",
    "# Description: A rule-based NLP project using Naive Bayes to classify Arabic \n",
    "#              product reviews. Features custom text normalization and \n",
    "#              N-gram vectorization to handle small-data context.\n",
    "# Maria Alsadiq\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Dataset Construction (Balanced Approach)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Creating a balanced dataset manually to prevent class bias (Positive vs Negative)\n",
    "csv_content = \"\"\"text,sentiment\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ Ø±Ø§Ø¦Ø¹ Ø¬Ø¯Ø§Ù‹ ÙˆØ£Ù†ØµØ­ Ø¨Ù‡,Positive\n",
    "Ø³Ø¹ÙŠØ¯ Ø¬Ø¯Ø§Ù‹ Ø¨Ù‡Ø°Ù‡ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø©,Positive\n",
    "Ø´ÙƒØ±Ø§Ù‹ Ù„ÙƒÙ… Ø¹Ù„Ù‰ Ø³Ø±Ø¹Ø© Ø§Ù„ØªÙˆØµÙŠÙ„,Positive\n",
    "Ø¬ÙˆØ¯Ø© Ù…Ù…ØªØ§Ø²Ø© ÙˆØ³Ø¹Ø± Ù…Ù†Ø§Ø³Ø¨,Positive\n",
    "Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù…ØªØ§Ø²Ø© ÙˆØ³Ø±ÙŠØ¹Ø©,Positive\n",
    "ÙˆØµÙ„ Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ø­Ø§Ù„Ø© Ø³Ù„ÙŠÙ…Ø© ÙˆØ¬ÙŠØ¯Ø©,Positive\n",
    "Ø§Ù„Ø¬Ù‡Ø§Ø² ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ù…ØªØ§Ø²,Positive\n",
    "ØªØ¬Ø±Ø¨Ø© Ø¬Ù…ÙŠÙ„Ø© ÙˆÙ…Ù…ØªØ¹Ø©,Positive\n",
    "Ù…Ù†ØªØ¬ Ø¬ÙŠØ¯ ÙˆÙŠØ³ØªØ­Ù‚ Ø§Ù„Ø´Ø±Ø§Ø¡,Positive\n",
    "ÙƒÙ„ Ø´ÙŠØ¡ ÙƒØ§Ù† Ù…Ø«Ø§Ù„ÙŠØ§Ù‹,Positive\n",
    "Ø£ÙØ¶Ù„ Ù…ØªØ¬Ø± ØªØ¹Ø§Ù…Ù„Øª Ù…Ø¹Ù‡,Positive\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ Ø¨Ø³Ø±Ø¹Ø© ÙˆÙ‡Ùˆ Ø¬ÙŠØ¯ Ø¬Ø¯Ø§,Positive\n",
    "Ø£Ø­Ø¨Ø¨Øª Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬ ÙƒØ«ÙŠØ±Ø§,Positive\n",
    "Ø§Ù„Ø®Ø§Ù…Ø© Ù…Ù…ØªØ§Ø²Ø© Ø¬Ø¯Ø§,Positive\n",
    "ØªÙˆØµÙŠÙ„ Ø³Ø±ÙŠØ¹ ÙˆØªØ¹Ø§Ù…Ù„ Ø±Ø§Ø¦Ø¹,Positive\n",
    "Ù…Ù†ØªØ¬ Ø£ØµÙ„ÙŠ ÙˆØ±Ø§Ø¦Ø¹,Positive\n",
    "Ø³Ø£Ø·Ù„Ø¨ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯,Positive\n",
    "ØªØ¬Ø±Ø¨Ø© Ø´Ø±Ø§Ø¦ÙŠØ© Ù†Ø§Ø¬Ø­Ø©,Positive\n",
    "Ø®Ø¯Ù…Ø© Ø±Ø§Ø¦Ø¹Ø© ÙˆØ³Ø±ÙŠØ¹Ø©,Positive\n",
    "Ø³Ø¹Ø± Ø±Ø®ÙŠØµ ÙˆØ¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ©,Positive\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ Ø¬Ù…ÙŠÙ„ Ø¬Ø¯Ø§Ù‹ ÙˆÙØ®Ù…,Positive\n",
    "Ø´ÙƒØ±Ø§ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø§Ù‚ÙŠ,Positive\n",
    "Ø£Ù†ØµØ­ Ø§Ù„Ø¬Ù…ÙŠØ¹ Ø¨Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ÙƒÙ…,Positive\n",
    "Ù…Ù†ØªØ¬ ÙŠØ³ØªØ­Ù‚ ÙƒÙ„ Ø±ÙŠØ§Ù„,Positive\n",
    "Ø§Ù„ØªØºÙ„ÙŠÙ Ù…Ù…ØªØ§Ø² ÙˆØ§Ù„Ù…Ù†ØªØ¬ Ø³Ù„ÙŠÙ…,Positive\n",
    "Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù‚Ù…Ø© ÙÙŠ Ø§Ù„Ø§Ø®Ù„Ø§Ù‚,Positive\n",
    "ØªØ¬Ø±Ø¨Ø© Ø¬Ù…ÙŠÙ„Ø© Ùˆ Ø§Ù„Ù…Ù†ØªØ¬ Ø¬ÙŠØ¯,Positive\n",
    "Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¬ÙŠØ¯Ù‡ Ø¬Ø¯Ø§,Positive\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ Ø³ÙŠØ¡ ÙˆÙ„Ø§ ÙŠØ¹Ù…Ù„,Negative\n",
    "Ø®Ø³Ø§Ø±Ø© ÙÙ„ÙˆØ³ Ø¹Ù„Ù‰ Ø§Ù„ÙØ§Ø¶ÙŠ,Negative\n",
    "Ø®Ø¯Ù…Ø© Ø³ÙŠØ¦Ø© Ø¬Ø¯Ø§Ù‹ ÙˆØªØ£Ø®ÙŠØ±,Negative\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ Ù…ÙƒØ³ÙˆØ±,Negative\n",
    "Ù„Ø§ Ø£Ù†ØµØ­ Ø¨Ø§Ù„Ø´Ø±Ø§Ø¡ Ø£Ø¨Ø¯Ø§Ù‹,Negative\n",
    "Ø§Ù„Ø¬ÙˆØ¯Ø© Ø±Ø¯ÙŠØ¦Ø© Ø¬Ø¯Ø§Ù‹,Negative\n",
    "ØªØ¬Ø±Ø¨Ø© Ù…Ø±ÙˆØ¹Ø© ÙˆÙ„Ù† Ø£ÙƒØ±Ø±Ù‡Ø§,Negative\n",
    "Ø£Ø³ÙˆØ£ ØªØ¬Ø±Ø¨Ø© ÙÙŠ Ø­ÙŠØ§ØªÙŠ,Negative\n",
    "ØªØºÙ„ÙŠÙ Ø³ÙŠØ¡ ÙˆØ§Ù„Ù…Ù†ØªØ¬ Ù…ØªØ¶Ø±Ø±,Negative\n",
    "Ø¨Ø·ÙŠØ¡ Ø¬Ø¯Ø§Ù‹ ÙˆÙŠØ¹Ù„Ù‚,Negative\n",
    "Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù„Ø§ ÙŠØ±Ø¯ÙˆÙ†,Negative\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ØµÙˆØ±Ø©,Negative\n",
    "ØªØ¬Ø±Ø¨Ø© Ø¬Ù…ÙŠÙ„Ø© Ù„ÙƒÙ† Ø§Ù„Ù…Ù†ØªØ¬ Ø³ÙŠØ¡,Negative\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ ØªØ§Ù„Ù,Negative\n",
    "Ù†Ø¯Ù…Øª Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø±Ø§Ø¡,Negative\n",
    "Ø¬ÙˆØ¯Ø© Ø³ÙŠØ¦Ø© Ø¬Ø¯Ø§ Ù„Ø§ Ø§Ù†ØµØ­ Ø¨Ù‡,Negative\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ Ù…Ù‚Ù„Ø¯ ÙˆÙ„ÙŠØ³ Ø£ØµÙ„ÙŠ,Negative\n",
    "ØªØ¬Ø±Ø¨Ø© ÙØ§Ø´Ù„Ø© Ø¨ÙƒÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³,Negative\n",
    "ÙƒØ§Ù†Øª Ø§Ù„ØªØ¬Ø±Ø¨Ø© ÙƒØ§Ø±Ø«ÙŠØ©,Negative\n",
    "ØªØ£Ø®ÙŠØ± ÙÙŠ Ø§Ù„Ø´Ø­Ù†Ø© ÙˆØªØºÙ„ÙŠÙ Ø³ÙŠØ¡,Negative\n",
    "Ù„Ù… ÙŠØ¹Ø¬Ø¨Ù†ÙŠ Ø§Ù„Ù…Ù†ØªØ¬ Ù†Ù‡Ø§Ø¦ÙŠØ§,Negative\n",
    "Ù„ÙˆÙ† Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ø§Ù‡Øª ÙˆØºÙŠØ± Ø¬ÙŠØ¯,Negative\n",
    "Ø®Ø§Ù…ØªÙ‡ Ø±Ø¯ÙŠØ¦Ø© Ø¬Ø¯Ø§ ÙˆØ³Ø¹Ø±Ù‡ ØºØ§Ù„ÙŠ,Negative\n",
    "Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ Ù…ÙƒØ³ÙˆØ± Ø§Ù„ÙƒØ±ØªÙˆÙ†,Negative\n",
    "Ø³ÙŠØ¡ Ø¬Ø¯Ø§ Ø¬Ø¯Ø§,Negative\n",
    "Ù„Ø§ ÙŠØ³ØªØ­Ù‚ Ø³Ø¹Ø±Ù‡,Negative\n",
    "Ø®Ø¯Ù…Ø© Ù…Ø§ Ø¨Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ¹ Ø³ÙŠØ¦Ø©,Negative\n",
    "\"\"\"\n",
    "\n",
    "# Saving dataset locally\n",
    "with open('arabic_reviews.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "print(\"Dataset created successfully.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. Data Preprocessing (Arabic Normalization)\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv('arabic_reviews.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes Arabic text by unifying different forms of letters.\n",
    "    -  (Ø£ØŒ Ø¥ØŒ Ø¢) -> Ø§\n",
    "    -  (Ø©) -> Ù‡\n",
    "    -  (Ù‰) -> ÙŠ\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[Ø£Ø¥Ø¢]', 'Ø§', text)\n",
    "    text = re.sub(r'Ø©', 'Ù‡', text)\n",
    "    text = re.sub(r'Ù‰', 'ÙŠ', text)\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Model Pipeline & Training\n",
    "# -----------------------------------------------------------------------------\n",
    "# Using N-grams (1,2) to capture context like \"not good\" or \"very bad\"\n",
    "model = make_pipeline(CountVectorizer(ngram_range=(1, 2)), MultinomialNB())\n",
    "\n",
    "# Splitting Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['sentiment'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Training\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model trained successfully.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. Evaluation & Live Testing\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- Live Inference ---\")\n",
    "test_cases = [\n",
    "    \"Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ Ø§Ù†Ù‡ Ø±Ø§Ø¦Ø¹\",           # Tricky case 1\n",
    "    \"Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ ÙˆÙ‡Ùˆ Ø³ÙŠØ¡ Ø¬Ø¯Ø§\",      # Tricky case 2\n",
    "    \"Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¬ÙŠØ¯Ù‡\",          # Normalization test\n",
    "    \"ÙƒØ§Ù†Øª Ø§Ù„ØªØ¬Ø±Ø¨Ø© ÙƒØ§Ø±Ø«ÙŠØ©\",        # Vocabulary test\n",
    "    \"ØªØ¬Ø±Ø¨Ø© Ø¬Ù…ÙŠÙ„Ø© Ùˆ Ø§Ù„Ù…Ù†ØªØ¬ Ø¬ÙŠØ¯\"    # Compound sentence\n",
    "]\n",
    "\n",
    "for text in test_cases:\n",
    "    cleaned = clean_text(text)\n",
    "    prediction = model.predict([cleaned])[0]\n",
    "    prob = model.predict_proba([cleaned]).max() * 100\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {prediction} (Confidence: {prob:.1f}%)\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "042aafd5-7845-4cf4-ac6e-40e8cc892a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠ (ØªØ¬Ø±Ø¨Ø© ØªÙØ§Ø¹Ù„ÙŠØ©) ---\n",
      "Ø§ÙƒØªØ¨ Ø¬Ù…Ù„ØªÙƒ Ù„Ù„ØªØ­Ù„ÙŠÙ„ØŒ Ø£Ùˆ Ø§ÙƒØªØ¨ 'Ø®Ø±ÙˆØ¬' Ù„Ù„Ø¥Ù†Ù‡Ø§Ø¡.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:  Ø§Ù„ØªØ¬Ø±Ø¨Ø© ÙƒØ§Ù†Øª Ø³ÙŠØ¦Ø©\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ø§Ù„Ù†Øµ: Ø§Ù„ØªØ¬Ø±Ø¨Ø© ÙƒØ§Ù†Øª Ø³ÙŠØ¦Ø©\n",
      "  Ø§Ù„ØªØ­Ù„ÙŠÙ„: Negative ğŸ˜¡\n",
      "  Ø§Ù„Ø«Ù‚Ø©: 89.4%\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:  Ù‡Ø°Ø§ Ø±Ø§Ø¦Ø¹ !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ø§Ù„Ù†Øµ: Ù‡Ø°Ø§ Ø±Ø§Ø¦Ø¹ !!\n",
      "  Ø§Ù„ØªØ­Ù„ÙŠÙ„: Positive  ğŸ˜ \n",
      "  Ø§Ù„Ø«Ù‚Ø©: 85.5%\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:  Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù„ÙŠØ³Øª Ø¬ÙŠØ¯Ø© \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ø§Ù„Ù†Øµ: Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù„ÙŠØ³Øª Ø¬ÙŠØ¯Ø© \n",
      "  Ø§Ù„ØªØ­Ù„ÙŠÙ„: Positive  ğŸ˜ \n",
      "  Ø§Ù„Ø«Ù‚Ø©: 90.2%\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:  Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¬ÙŠØ¯Ø©\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ø§Ù„Ù†Øµ: Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¬ÙŠØ¯Ø©\n",
      "  Ø§Ù„ØªØ­Ù„ÙŠÙ„: Positive  ğŸ˜ \n",
      "  Ø§Ù„Ø«Ù‚Ø©: 94.7%\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:  Ø§Ù„Ø±Ø¯ÙˆØ¯ ÙƒØ§Ù†Øª Ø³ÙŠØ¦Ø©\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ø§Ù„Ù†Øµ: Ø§Ù„Ø±Ø¯ÙˆØ¯ ÙƒØ§Ù†Øª Ø³ÙŠØ¦Ø©\n",
      "  Ø§Ù„ØªØ­Ù„ÙŠÙ„: Negative ğŸ˜¡\n",
      "  Ø§Ù„Ø«Ù‚Ø©: 89.1%\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:  Ø®Ø±ÙˆØ¬\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ø´ÙƒØ±Ø§ Ù„Ùƒ \n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. Interactive Mode (Try it yourself!) \n",
    "# ==========================================\n",
    "print(\"\\n--- Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠ (ØªØ¬Ø±Ø¨Ø© ØªÙØ§Ø¹Ù„ÙŠØ©) ---\")\n",
    "print(\"Ø§ÙƒØªØ¨ Ø¬Ù…Ù„ØªÙƒ Ù„Ù„ØªØ­Ù„ÙŠÙ„ØŒ Ø£Ùˆ Ø§ÙƒØªØ¨ 'Ø®Ø±ÙˆØ¬' Ù„Ù„Ø¥Ù†Ù‡Ø§Ø¡.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§: \")\n",
    "   \n",
    "    if user_input.lower() in ['Ø®Ø±ÙˆØ¬', 'exit', 'quit']:\n",
    "        print(\" Ø´ÙƒØ±Ø§ Ù„Ùƒ \")\n",
    "        break\n",
    "        \n",
    "    if not user_input.strip():\n",
    "        continue\n",
    "\n",
    "    cleaned_input = clean_text(user_input)\n",
    "    \n",
    "    prediction = model.predict([cleaned_input])[0]\n",
    "    \n",
    "    prob = model.predict_proba([cleaned_input]).max() * 100\n",
    "\n",
    "    emoji = \" ğŸ˜ \" if prediction == \"Positive\" or prediction == \"Ø¥ÙŠØ¬Ø§Ø¨ÙŠ\" else \"ğŸ˜¡\"\n",
    "    print(f\"  Ø§Ù„Ù†Øµ: {user_input}\")\n",
    "    print(f\"  Ø§Ù„ØªØ­Ù„ÙŠÙ„: {prediction} {emoji}\")\n",
    "    print(f\"  Ø§Ù„Ø«Ù‚Ø©: {prob:.1f}%\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67d206-333c-4ea7-9c6b-444b7ea2bd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2025.12-py312",
   "language": "python",
   "name": "conda-env-anaconda-ai-2025.12-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
